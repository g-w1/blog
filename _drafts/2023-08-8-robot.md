---
layout: post
title: "Why it's necessary to shoot yourself in the foot"
date: 2023-08-08 18:44:32 +0300
categories: observation
tags: thought-experiment
---

*[Epistemic Status: I know that there is probably lots of writing about this topic, but I wanted to think about it for myself so that I could 1) maybe come up with a new idea 2) have fun :)].*

I was recently thinking about the thought experiment that Yudkowsky poses in [Beyond the Reach of God](https://www.readthesequences.com/Beyond-The-Reach-Of-God) and thought of a yes-or-no question that has incredible implications if it is true or not.

I'll first summarize my question, so you don't need to read [Beyond the Reach of God](https://www.readthesequences.com/Beyond-The-Reach-Of-God), but if you want to, you can.

Imagine that humans have the technology to scan someone's brain and then upload it into a computer and run it on the computer. Once they hook up the correct signals to all the nerves in the brain, they find that it works. They find that the person's behavior is 100% accurate to what the real-world person would do, given the exact same electrical impulses to the nerves. But the researchers have a problem: they want to know if it is ethical to extract labor out of the virtual person wihout giving them a rest (it turns out that you can modify an emulated person so that they don't need sleep, but it just seems very unpleasant to them.) The next logical step is to ask the person if they can feel the pain of sleep deprivation. But the researchers then realize that of course the emulated person would say yes because their behavior is 100% accurate to the behavior of the real person. They need a way to determine if they are acutally going to cause pain to the person.

Spoiler alert: I don't know how to answer the above question, and while I think that it can be solved, it's way above my pay grade. Instead I'm going to investigate the consequences of the two (yes/no) outcomes of the above question. I think either outcome has some very interesting consequences (TODO eliminate repitition of consequences).

1) The person inside the machine feels the pain of sleeplesness and sees redness in red. We have to treat them with the same rights as a real-life human.

First of all, until we know for sure, this should be the default way we understand emulations. However, when extrapolated, this outcome has some really wacky outcomes.

Since all you need to simulate an emulation is a computer, which is really just a Turing Machine (or by the Church-Turing Thesis, a lot of things) it means that these sort of qualia can arise from pure mathematics. In fact, this thought was the reason I wrote this essay. The idea that *qualia* were possible just by a machine doing calculations was wild. If it were true, it would mean that humans are not that special after all. But also, taking it a step further, since in this world "qualia" are just math, if you believe that math exists outside of our reality, it would mean that TODO continue this thought.


1) The person inside the machine cannot feel the pain of sleeplesness or see the redness in red. It's moral to extract labor or anything from the emulation.
